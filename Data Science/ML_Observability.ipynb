{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4d192a-ebd2-41f7-a992-55e5e40c68bc",
   "metadata": {
    "collapsed": false,
    "name": "Title",
    "resultHeight": 943
   },
   "source": [
    "![](https://www.snowflake.com/wp-content/themes/snowflake/assets/img/brand-guidelines/logo-sno-blue-example.svg)\n",
    "\n",
    "# Build, Deploy and Monitor your Model in Snowflake\n",
    "\n",
    "In this demo we will be showcasing how a complete model life cycle looks like in Snowflake. We will be using the following capabilities in Snowflake,\n",
    "\n",
    "* Snowflake ML Python SDK\n",
    "* Model Registry\n",
    "* ML Observability\n",
    "* Alerts\n",
    "* Drift Monitoring\n",
    "\n",
    "![](https://drive.google.com/file/d/1jWryVEAjyetHMRgTTMo_bnx_BZRdeNuC/view?usp=sharing)\n",
    "\n",
    ">**Use case:** A financial institution has been dealing with loss of customers to competition. They want to understand the likelihood of each of their customer's churning so that they can take necessary action for users with high probablity of churning.Over a period of time there is a new trend seen in customer churn which needs to be actionized immediately to gain competitive advantage. The financial institution leverages the ML Observability dashboard to view the metrics and accuracy factors. It can take proactive action for retraining the model and is also able to compare different model version by monitoring the model performance.\n",
    "\n",
    "### **Features**\n",
    "\n",
    "* **CREDITSCORE:** Credit score of the customer based on their historical credit behavior and management  \n",
    "* **GEOGRAPHY:** Country of residence\n",
    "* **GENDER:** Gender of the customer\n",
    "* **AGE:** Age of the customer\n",
    "* **TENURE:** Duration in years that they have been a customer\n",
    "* **BALANCE:** Current balance of their bankaccount\n",
    "* **NUMOFPRODUCTS:** Number of products purchased from the bank\n",
    "* **HASCRCARD:** Does the customer have a credit card? - 1 if they do, 0 if they don't\n",
    "* **ISACTIVEMEMBER:** Has the customer used their bank account in the last 3 months? - 1 if they did, 0 if they didn't\n",
    "* **ESTIMATEDSALARY:** Estimated salary of the customer\n",
    "* **DEBTTOINCOME:** Debt to income ratio\n",
    "\n",
    "### **Model**\n",
    "\n",
    "We will build a classification model using XGBoost framework with Snowflake ML API and log the model to registry. Along the way we will create model monitors and view the model performance in Snowsight dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "importheaders",
    "resultHeight": 54
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "from datetime import datetime, timedelta\n",
    "from snowflake.ml.registry import Registry\n",
    "import joblib\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import snowflake.ml.modeling.preprocessing as pp\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.snowpark.types import StringType, IntegerType\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, random, floor,current_date, datediff\n",
    "\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"mlops_customerchurn\", \"version\":{\"major\":1, \"minor\":0}}\n",
    "\n",
    "import snowflake.snowpark.functions as F\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "solution_prefix = session.get_current_warehouse()\n",
    "solution_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51a542-d06f-42fc-ad28-2f408f940b04",
   "metadata": {
    "collapsed": false,
    "name": "load_data",
    "resultHeight": 46
   },
   "source": [
    "### Load synthetic data from the data_stage into a Snowflake table using a COPY INTO command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8a2ccd3-075f-4a1e-9ab0-00e248cc9e4e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "initial_customer_dataset",
    "resultHeight": 111
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total exited customers: 1714 (Target: ~2000)\n",
      "   CustomerId  Surname  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
      "0           1    Johns          402    France    Male   55       9   91944.03   \n",
      "1           2  Schultz          735     Spain    Male   59       8  126536.56   \n",
      "2           3    Jones          570     Spain    Male   54       7  191357.66   \n",
      "3           4    Baker          406    France  Female   73       3  125263.00   \n",
      "4           5  Aguirre          371     Spain    Male   88       9  195626.75   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1         36899.18       0   \n",
      "1              2          0               0         33120.74       0   \n",
      "2              2          1               1         34751.09       1   \n",
      "3              4          0               0        169844.77       0   \n",
      "4              4          0               1         13787.72       0   \n",
      "\n",
      "  TransactionTimestamp  debttoincome  \n",
      "0  2022-01-09 14:08:54            23  \n",
      "1  2022-04-19 06:29:13            80  \n",
      "2  2022-07-11 11:43:59            29  \n",
      "3  2022-12-03 05:38:57            24  \n",
      "4  2022-10-30 09:17:13            80  \n"
     ]
    }
   ],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "    \n",
    "CREATE OR REPLACE STAGE data_stage\n",
    "    FILE_FORMAT = (TYPE = 'CSV') \n",
    "    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/mlops_customerchurn.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @data_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5283d28-3f4b-4247-93c3-43dc4e305315",
   "metadata": {
    "collapsed": false,
    "name": "read_csv_file",
    "resultHeight": 46
   },
   "source": [
    "### Read a CSV file using Snowpark from a stage in Snowflake into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a349023c-8855-4b60-8bdd-35ec51c48141",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "CUSTOMERS_DATA",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "spdf = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@data_stage\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77670b-0bfb-4824-8b80-b12a0948b8a4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cast"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import DecimalType, FloatType, DoubleType\n",
    "\n",
    "# Get schema of the DataFrame\n",
    "schema = spdf.schema.fields\n",
    "\n",
    "# Identify columns that are of type NUMBER (DecimalType)\n",
    "num_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n",
    "\n",
    "# Convert columns to FLOAT\n",
    "for col in num_columns:\n",
    "    spdf = spdf.with_column(col, spdf[col].cast(DoubleType()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca65646-6250-41ec-bdae-277bc86e7b44",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "date_advance"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, to_date,lit\n",
    "\n",
    "# Step 1: Get today's date\n",
    "todays_date = datetime.now()\n",
    "\n",
    "latest_date = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n",
    "\n",
    "# Step 3: Calculate the difference in days\n",
    "diff_days = (todays_date - latest_date).days - 1\n",
    "\n",
    "df = spdf.with_column(\n",
    "    \"TRANSACTIONTIMESTAMP\", \n",
    "    dateadd(\"day\", lit(diff_days), col(\"TRANSACTIONTIMESTAMP\"))\n",
    ")\n",
    "\n",
    "\n",
    "df = df.with_column(\n",
    "    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n",
    ")\n",
    "df = df.with_column(\n",
    "    \"PREDICTED_CHURN\", F.lit(9999)\n",
    ")\n",
    "df.show()\n",
    "\n",
    "df.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4b2b17b-ba3b-4eb0-b302-585f066f87ab",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "remove_rownum",
    "resultHeight": 350
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMERID\"  |\"CREDITSCORE\"  |\"GEOGRAPHY\"  |\"GENDER\"  |\"AGE\"  |\"TENURE\"  |\"BALANCE\"  |\"NUMOFPRODUCTS\"  |\"HASCRCARD\"  |\"ISACTIVEMEMBER\"  |\"ESTIMATEDSALARY\"  |\"EXITED\"  |\"TRANSACTIONTIMESTAMP\"  |\"DEBTTOINCOME\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1             |402            |France       |Male      |55     |9         |91944.03   |1                |1            |1                 |36899.18           |0         |2022-01-09 14:08:54     |23              |\n",
      "|2             |735            |Spain        |Male      |59     |8         |126536.56  |2                |0            |0                 |33120.74           |0         |2022-04-19 06:29:13     |80              |\n",
      "|3             |570            |Spain        |Male      |54     |7         |191357.66  |2                |1            |1                 |34751.09           |1         |2022-07-11 11:43:59     |29              |\n",
      "|4             |406            |France       |Female    |73     |3         |125263.0   |4                |0            |0                 |169844.77          |0         |2022-12-03 05:38:57     |24              |\n",
      "|5             |371            |Spain        |Male      |88     |9         |195626.75  |4                |0            |1                 |13787.72           |0         |2022-10-30 09:17:13     |80              |\n",
      "|6             |320            |Germany      |Male      |72     |7         |28858.19   |3                |1            |0                 |48456.88           |0         |2023-11-26 06:10:34     |95              |\n",
      "|7             |421            |Spain        |Male      |71     |6         |15990.69   |3                |1            |0                 |191619.44          |1         |2022-10-02 08:53:11     |49              |\n",
      "|8             |766            |Spain        |Male      |39     |4         |39715.24   |1                |0            |1                 |22544.05           |0         |2022-01-17 10:34:53     |76              |\n",
      "|9             |514            |Spain        |Male      |44     |6         |193003.03  |3                |1            |1                 |16901.08           |0         |2022-01-15 01:31:26     |52              |\n",
      "|10            |630            |France       |Female    |64     |6         |189832.56  |3                |1            |1                 |83592.57           |0         |2023-12-09 06:53:42     |56              |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spdf= df.drop('ROWNUMBER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f72cd-5892-4656-ae23-3db6ffb1cd8e",
   "metadata": {
    "collapsed": false,
    "name": "preprocessing",
    "resultHeight": 66
   },
   "source": [
    "#### Define a preprocessing pipeline using Pipeline with two steps: Ordinal Encoding for categorical columns and Min-Max Scaling for numerical columns. It then splits the data into training and testing sets, applies the preprocessing steps to the training data, and saves the pipeline as a joblib file (preprocessing_pipeline.joblib) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92413c3-0dea-4d98-a70a-0c77c72b0397",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "preprocessing_pipeline",
    "resultHeight": 287
   },
   "outputs": [],
   "source": [
    "num_cols = ['ESTIMATEDSALARY', 'BALANCE', 'CREDITSCORE','AGE','TENURE','DEBTTOINCOME']\n",
    "output_cols=['EstimatedSalary_SS', 'Balance_SS', 'CreditScore_SS','Age_SS','Tenure_SS','debttoincome_SS']\n",
    "\n",
    "cat_cols = ['HasCrCard', 'IsActiveMember', 'Geography','Gender', 'NumOfProducts']\n",
    "string_columns = ['GEOGRAPHY', 'GENDER']\n",
    "string_columns_oe = ['GEOGRAPHY_oe', 'GENDER_oe']\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "            (\n",
    "                \"OE\",\n",
    "                pp.OrdinalEncoder(\n",
    "                    input_cols=string_columns,\n",
    "                    output_cols=string_columns_oe,\n",
    "                    drop_input_cols= False,\n",
    "                )\n",
    "                \n",
    "            ),\n",
    "            (\n",
    "                \"MMS\",\n",
    "                pp.MinMaxScaler(\n",
    "                    clip=True,\n",
    "                    input_cols=num_cols,\n",
    "                    output_cols=output_cols,\n",
    "                    drop_input_cols= False,\n",
    "                )\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "\n",
    "PIPELINE_FILE = '/tmp/preprocessing_pipeline.joblib'\n",
    "joblib.dump(preprocessing_pipeline, PIPELINE_FILE) # We are just pickling it locally first\n",
    "training, testing = spdf.random_split(weights=[0.8, 0.2], seed=111)\n",
    "training_spdf = preprocessing_pipeline.fit(training).transform(training)\n",
    "testing_spdf=preprocessing_pipeline.fit(testing).transform(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5deeba5-4197-4a01-b93a-c797cbe13925",
   "metadata": {
    "collapsed": false,
    "name": "save_pipeline",
    "resultHeight": 47
   },
   "source": [
    "#### Store the pipeline file in a stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6772-3e92-49c1-a969-6f8a03ba7c8a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "ml_stage",
    "resultHeight": 354
   },
   "outputs": [],
   "source": [
    "session.sql(\"CREATE or replace stage ML_STAGE\").collect()\n",
    "session.file.put(PIPELINE_FILE, \"@ML_STAGE\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15b984-9294-4e35-a76e-1e6210653ed9",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "view_stage",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "ls @ML_STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bc115-40c0-4012-a5f5-c0a92b28e0fa",
   "metadata": {
    "collapsed": false,
    "name": "build_model",
    "resultHeight": 60
   },
   "source": [
    "## Build the XGBClassifier model and train using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7af4a413-9d63-497e-a7a3-237553a363e1",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____initial_training",
    "resultHeight": 671
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.dataframe.DataFrame at 0x33cc21a60>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n",
    "\n",
    "cat_cols = ['HasCrCard', 'IsActiveMember', 'GEOGRAPHY','GENDER', 'NumOfProducts']\n",
    "Target = [\"EXITED\"]\n",
    "\n",
    "feature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\",\"ESTIMATEDSALARY\", \"BALANCE\", \"CREDITSCORE\",\"AGE\",\"TENURE\",\"DEBTTOINCOME\",\"GEOGRAPHY\",\"GENDER\",\"PREDICTED_CHURN\"]]\n",
    "\n",
    "\n",
    "training_spdf = training_spdf.with_column(\n",
    "    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n",
    ")\n",
    "output_label = [\"PREDICTED_CHURN\"]\n",
    "# Initialize a XGBClassifier object with input, label, and output column names\n",
    "model = XGBClassifier(\n",
    "    input_cols=feature_names_input,\n",
    "    label_cols=Target,\n",
    "    output_cols=output_label\n",
    "    \n",
    ")\n",
    "\n",
    "# Train the classifier model using the training set\n",
    "_ = model.fit(training_spdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86a6fb-7dba-4ba0-91b7-a0428301b3f2",
   "metadata": {
    "collapsed": false,
    "name": "init_registry",
    "resultHeight": 46
   },
   "source": [
    "### Initalize Snowflake Model Registry\n",
    "\n",
    "Log and manage the trained machine learning model in Snowflake.\n",
    "\n",
    "Notice the task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION: Specifies that this is a binary classification task (predicting churn: Yes/No)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b1cba-2e57-4508-9601-9955ac7a830e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DEMO____log_model",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.model import type_hints\n",
    "\n",
    "reg = Registry(session=session)\n",
    "\n",
    "MODEL_NAME = \"QS_CustomerChurn_classifier\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "\n",
    "mv = reg.log_model(model,\n",
    "                   model_name=MODEL_NAME,\n",
    "                   version_name=MODEL_VERSION,\n",
    "                   options={'relax_version': True},\n",
    "                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\n",
    "reg.show_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bde85-0531-4ec5-b0ac-6b3baf7502fd",
   "metadata": {
    "collapsed": false,
    "name": "inference_fn",
    "resultHeight": 60
   },
   "source": [
    "## Ongoing inference\n",
    "The inference function performs predictions using a pre-trained machine learning model in Snowflake. This function uses the preprocessing pipeline created earlier to ensure data is transformed consistently.\n",
    "âœ… Runs predictions using a registered model version.\n",
    "âœ… Updates predictions directly into the Snowflake table.\n",
    "âœ… Efficiently handles batch inference with SQL updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709bd3d-7c4d-4bc3-aa99-ba3ea627ec31",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "inference_utils",
    "resultHeight": 432
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import snowflake.ml.modeling.preprocessing as pp\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "def inference(table_name, modelname, modelversion) -> str:\n",
    "    reg = Registry(session=session)\n",
    "    m = reg.get_model(modelname)\n",
    "    mv = m.version(modelversion)\n",
    "    \n",
    "    # Load preprocessing pipeline from a file\n",
    "    session.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\n",
    "    pipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n",
    "    \n",
    "    \n",
    "    preprocessing_pipeline = joblib.load(pipeline_file)\n",
    "    \n",
    "    df = session.table(table_name)\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    testing_spdf = preprocessing_pipeline.fit(df).transform(df)\n",
    "    testing_spdf = testing_spdf.with_column(\n",
    "    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n",
    ")\n",
    "    # Perform prediction\n",
    "    results = mv.run(testing_spdf, function_name=\"predict\")\n",
    "    results =results.drop(\"CREDITSCORE_SS\", \"BALANCE_SS\", \"DEBTTOINCOME_SS\", \"TENURE_SS\", \"AGE_SS\", \"ESTIMATEDSALARY_SS\", \"GENDER_OE\", \"GEOGRAPHY_OE\")\n",
    "    #results.write.save_as_table(\"customer_churn\", mode=\"overwrite\")\n",
    "    results.create_or_replace_temp_view(\"results_temp\")\n",
    "    update_statement = f\"\"\"\n",
    "    UPDATE {table_name} t\n",
    "    SET PREDICTED_CHURN = r.PREDICTED_CHURN\n",
    "    FROM results_temp r\n",
    "    WHERE t.CUSTOMERID = r.CUSTOMERID\n",
    "    AND t.TRANSACTIONTIMESTAMP=r.TRANSACTIONTIMESTAMP;\n",
    "\"\"\"\n",
    "\n",
    "    # Execute the merge statement\n",
    "    session.sql(update_statement).collect()\n",
    "        \n",
    "    return \"Success\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12894ad5-c3a5-411d-bea7-7037fc9521d1",
   "metadata": {
    "collapsed": false,
    "name": "mkpredict1"
   },
   "source": [
    "Execute the trained model on the testing_spdf DataFrame using mv.run().\n",
    "function_name=\"predict\" specifies that the function to be used for inference is \"predict\", \n",
    "The output is a DataFrame containing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4955a-9eda-4eb9-99eb-9156b526998a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "inference_results"
   },
   "outputs": [],
   "source": [
    "testing_spdf = testing_spdf.with_column(\n",
    "    \"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n",
    ")\n",
    "# Perform prediction\n",
    "results = mv.run(testing_spdf, function_name=\"predict\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb54964-9adb-416d-898f-4e61a169bca2",
   "metadata": {
    "collapsed": false,
    "name": "SIMULATION"
   },
   "source": [
    "## DATA DRIFT AND OBSERVABILITY IN ML OBSERVABILITY DASHBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcea649-de3b-4859-81fb-338d5d9fc007",
   "metadata": {
    "collapsed": false,
    "name": "mkdrift"
   },
   "source": [
    "Now lets see how a data drift can be monitored and proactive action could help the financial firm to prevent customer churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f4936-3811-4ecf-b737-e33fbca0afa0",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "read_drift_data"
   },
   "outputs": [],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "    \n",
    "CREATE OR REPLACE STAGE data_stage\n",
    "    FILE_FORMAT = (TYPE = 'CSV') \n",
    "    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/CUSTOMERS_DRIFTED.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @data_stage;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841cf81-4e9c-4929-bc9e-89a9af3c9d3a",
   "metadata": {
    "collapsed": false,
    "name": "mkcustdrift"
   },
   "source": [
    "The data in CUSTOMERS_DRIFTED file contains new customer trends leading to poor accuracy from inference using the v1 version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71246d5a-ad5f-4804-98c9-d423047f9bd0",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "datatype_Cast"
   },
   "outputs": [],
   "source": [
    "spdf = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@data_stage\")\n",
    "\n",
    "from snowflake.snowpark.types import DecimalType, FloatType\n",
    "\n",
    "# Get schema of the DataFrame\n",
    "schema = spdf.schema.fields\n",
    "\n",
    "# Identify columns that are of type NUMBER (DecimalType)\n",
    "num_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n",
    "\n",
    "# Convert columns to FLOAT\n",
    "for col in num_columns:\n",
    "    spdf = spdf.with_column(col, spdf[col].cast(FloatType()))\n",
    "\n",
    "\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, to_date, lit,to_timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Get today's date\n",
    "todays_date = datetime.now()\n",
    "\n",
    "# Ensure TRANSACTIONTIMESTAMP is stored as a string first\n",
    "spdf = spdf.with_column(\"TRANSACTIONTIMESTAMP\", col(\"TRANSACTIONTIMESTAMP\").cast(\"string\"))\n",
    "\n",
    "# Get the latest date from the dataset\n",
    "latest_date_str = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n",
    "\n",
    "# Convert latest_date to datetime\n",
    "latest_date = datetime.strptime(latest_date_str, '%m/%d/%y %H:%M')\n",
    "\n",
    "# Step 3: Calculate the difference in days\n",
    "diff_days = (todays_date - latest_date).days - 1\n",
    "\n",
    "# Apply date adjustment\n",
    "df = spdf.with_column(\n",
    "    \"TRANSACTIONTIMESTAMP\",\n",
    "    dateadd(\"day\", lit(diff_days), to_timestamp(col(\"TRANSACTIONTIMESTAMP\"), 'MM/DD/YY HH24:MI'))\n",
    ")\n",
    "\n",
    "# Cast CREDIT SCORE to float\n",
    "df = df.with_column(\"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\"))\n",
    "\n",
    "# Add PREDICTED_CHURN column\n",
    "spdf_drift = df.with_column(\"PREDICTED_CHURN\", lit(9999))\n",
    "\n",
    "spdf_drift.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292f2b9-e023-4d96-bef2-f183ebf97fe6",
   "metadata": {
    "collapsed": false,
    "name": "mk1"
   },
   "source": [
    "The financial firm carries the predictions with the drifted data using the model version v1. The drifted data is saved in CUSTOMERS_DRIFTED table. A copy of the same data is saved in the CUSTOMERS_EVAL table to show how that drift was monitored and a new model retrained proactively to avert inaccurate decision making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d791e8-e863-4842-b7f8-835a12072837",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CUSTOMERS_DRIFTED_table"
   },
   "outputs": [],
   "source": [
    "\n",
    "current_columns = spdf_drift.columns \n",
    "new_columns = [col.strip('\"') for col in current_columns] \n",
    "\n",
    "spdf_drift = spdf_drift.select([spdf_drift[col].alias(new_col) for col, new_col in zip(current_columns, new_columns)])\n",
    "spdf_drift = spdf_drift.with_column(\n",
    "    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n",
    ")\n",
    "spdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_DRIFTED\")\n",
    "spdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_EVAL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce8079-4ddd-41df-a8cb-b867deb7098b",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Monitoring",
    "resultHeight": 115
   },
   "source": [
    "# Enable Monitoring\n",
    "Create a model monitor using the CREATE MODEL MONITOR command. The monitor object automatically refreshes the monitor logs by querying source data and updates the monitoring reports based on the logs. The first one that is commented out shows the pythonic method and the next cell shows how to monitor using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75f3e5-e8b1-495a-bb89-522f2f8dc191",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "pythonic_modelmonitor"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "reg = Registry(session=session,options={\"enable_monitoring\": True})\n",
    "modelname='QS_CustomerChurn_classifier'\n",
    "modelversion='v1'\n",
    "m = reg.get_model(modelname)\n",
    "mv = m.version(modelversion)\n",
    "\n",
    "# Fetch model version that will be monitored\n",
    "model_version = mv\n",
    "\n",
    "from snowflake.ml.monitoring.entities.model_monitor_config import ModelMonitorConfig, ModelMonitorSourceConfig\n",
    "source_config = ModelMonitorSourceConfig(\n",
    "    source=\"CUSTOMERS_DRIFTED\",\n",
    "    baseline=\"CUSTOMERS\",\n",
    "    timestamp_column=\"TRANSACTIONTIMESTAMP\",\n",
    "    prediction_class_columns=[\"PREDICTED_CHURN\"],\n",
    "    actual_class_columns=[\"EXITED\"],\n",
    "    id_columns=[\"CUSTOMERID\"],\n",
    ")\n",
    "\n",
    "# Set up config for ModelMonitor.\n",
    "model_monitor_config = ModelMonitorConfig(\n",
    "    model_version=model_version,\n",
    "    model_function_name=\"predict\",\n",
    "    background_compute_warehouse_name=\"ml_wh\",\n",
    ")\n",
    "\n",
    "# Add a new ModelMonitor\n",
    "model_monitor = reg.add_monitor(\n",
    "    name=f\"CHURN_MODEL_MONITOR\", \n",
    "    source_config=source_config,\n",
    "    model_monitor_config=model_monitor_config,\n",
    ")\n",
    "model_monitor\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feedabf-0d1b-4efa-af01-9b3a38df68ea",
   "metadata": {
    "collapsed": false,
    "name": "sqlmm"
   },
   "source": [
    "## SQL Version for creating the model monitor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047644f-ab0a-4447-b573-2afd3c20f739",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DEMO____ADD_MONITOR",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL=QS_CustomerChurn_classifier\n",
    "    VERSION=v1\n",
    "    FUNCTION=predict\n",
    "    SOURCE=CUSTOMERS_DRIFTED\n",
    "    BASELINE=CUSTOMERS\n",
    "    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n",
    "    ACTUAL_CLASS_COLUMNS=(EXITED)\n",
    "    ID_COLUMNS=(CUSTOMERID)\n",
    "    WAREHOUSE=ML_WH\n",
    "    REFRESH_INTERVAL='1 min'\n",
    "    AGGREGATION_WINDOW='1 day';\n",
    "\"\"\"\n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb50723-976e-4be4-934a-2845f4208a6b",
   "metadata": {
    "collapsed": false,
    "name": "predict2"
   },
   "source": [
    "## Predict the churn for the new customer trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4e58d-10a2-4754-a750-6018310caf4f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "inference_1"
   },
   "outputs": [],
   "source": [
    "status= inference('CUSTOMERS_DRIFTED','QS_CUSTOMERCHURN_CLASSIFIER', 'v1');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e6b74-699e-4b7a-b281-0aa6ca925b79",
   "metadata": {
    "collapsed": false,
    "name": "DEMO____Dashboard",
    "resultHeight": 83
   },
   "source": [
    "Let us check how the churn predictions and the metrics look like. Open the Dashboard by navigating to Studio->Models\n",
    "\n",
    "Click on your model and choose the monitor that you just added above.Change the date range to \"Last 3 months\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc285676-763b-4bf8-91e9-b123f2774e84",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "RETRAINING_DATA"
   },
   "outputs": [],
   "source": [
    "-- Create csv format\n",
    "CREATE FILE FORMAT IF NOT EXISTS CSVFORMAT \n",
    "    SKIP_HEADER = 1 \n",
    "    TYPE = 'CSV';\n",
    "    \n",
    "CREATE OR REPLACE STAGE data_stage\n",
    "    FILE_FORMAT = (TYPE = 'CSV') \n",
    "    URL = 's3://sfquickstarts/sfguide_getting_started_with_ml_observability_in_snowflake/CUSTOMERS_TRAINING.csv';\n",
    "    \n",
    "-- Inspect content of stage\n",
    "LS @data_stage;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39a9f9-be64-491d-8df3-595c3bbf51d6",
   "metadata": {
    "collapsed": false,
    "name": "mkretrain"
   },
   "source": [
    "## It can be found by data drift and concept drift has significantly impacted the model's performance over time. To maintain accuracy, models require retraining periodically. Below is how this is handled in the customer churn prediction pipeline. Let us now retrain the data on the new trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71c4a1-fd06-42c5-8af7-1483ce44fae3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "preprocess_retraining_data"
   },
   "outputs": [],
   "source": [
    "spdf = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@data_stage\")\n",
    "\n",
    "from snowflake.snowpark.types import DecimalType, FloatType\n",
    "\n",
    "# Get schema of the DataFrame\n",
    "schema = spdf.schema.fields\n",
    "\n",
    "# Identify columns that are of type NUMBER (DecimalType)\n",
    "num_columns = [col.name for col in schema if isinstance(col.datatype, DecimalType)]\n",
    "\n",
    "# Convert columns to FLOAT\n",
    "for col in num_columns:\n",
    "    spdf = spdf.with_column(col, spdf[col].cast(FloatType()))\n",
    "\n",
    "\n",
    "from snowflake.snowpark.functions import col, current_date, dateadd, to_date, lit,to_timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Get today's date\n",
    "todays_date = datetime.now()\n",
    "\n",
    "# Ensure TRANSACTIONTIMESTAMP is stored as a string first\n",
    "spdf = spdf.with_column(\"TRANSACTIONTIMESTAMP\", col(\"TRANSACTIONTIMESTAMP\").cast(\"string\"))\n",
    "\n",
    "# Get the latest date from the dataset\n",
    "latest_date_str = max(spdf.select('TRANSACTIONTIMESTAMP').collect())[0]\n",
    "\n",
    "# Convert latest_date to datetime\n",
    "latest_date = datetime.strptime(latest_date_str, '%m/%d/%y %H:%M')\n",
    "\n",
    "# Step 3: Calculate the difference in days\n",
    "diff_days = (todays_date - latest_date).days - 1\n",
    "\n",
    "# Apply date adjustment\n",
    "df = spdf.with_column(\n",
    "    \"TRANSACTIONTIMESTAMP\",\n",
    "    dateadd(\"day\", lit(diff_days), to_timestamp(col(\"TRANSACTIONTIMESTAMP\"), 'MM/DD/YY HH24:MI'))\n",
    ")\n",
    "\n",
    "# Cast CREDIT SCORE to float\n",
    "df = df.with_column(\"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\"))\n",
    "\n",
    "# Add PREDICTED_CHURN column\n",
    "spdf_drift = df.with_column(\"PREDICTED_CHURN\", lit(9999))\n",
    "\n",
    "spdf_drift.show()\n",
    "\n",
    "current_columns = spdf_drift.columns \n",
    "new_columns = [col.strip('\"') for col in current_columns] \n",
    "\n",
    "spdf_drift = spdf_drift.select([spdf_drift[col].alias(new_col) for col, new_col in zip(current_columns, new_columns)])\n",
    "spdf_drift = spdf_drift.with_column(\n",
    "    \"CREDITSCORE\", col(\"CREDITSCORE\").cast(\"float\")\n",
    ")\n",
    "\n",
    "\n",
    "spdf_drift.write.mode(\"overwrite\").save_as_table(\"CUSTOMERS_TRAINING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a756567-1ec8-454b-b58d-d7c037f8d01c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "retrain_model"
   },
   "outputs": [],
   "source": [
    "# Load preprocessing pipeline from a file\n",
    "session.file.get('@ML_STAGE/preprocessing_pipeline.joblib.gz', '/tmp')\n",
    "pipeline_file = '/tmp/preprocessing_pipeline.joblib.gz'\n",
    "\n",
    "\n",
    "preprocessing_pipeline = joblib.load(pipeline_file)\n",
    "\n",
    "# Apply preprocessing\n",
    "training_spdf = preprocessing_pipeline.fit(spdf_drift).transform(spdf_drift)\n",
    "training_spdf = training_spdf.with_column(\n",
    "\"CREDITSCORE_SS\", col(\"CREDITSCORE_SS\").cast(\"float\")\n",
    ")\n",
    "\n",
    "num_cols = ['EstimatedSalary', 'Balance', 'CreditScore','Age','Tenure','debttoincome']\n",
    "\n",
    "cat_cols = ['HasCrCard', 'IsActiveMember', 'GEOGRAPHY','GENDER', 'NumOfProducts']\n",
    "Target = [\"EXITED\"]\n",
    "\n",
    "feature_names_input = [c for c in training_spdf.columns if c not in [\"EXITED\", \"TRANSACTIONTIMESTAMP\", \"CUSTOMERID\",\"ESTIMATEDSALARY\", \"BALANCE\", \"CREDITSCORE\",\"AGE\",\"TENURE\",\"DEBTTOINCOME\",\"GEOGRAPHY\",\"GENDER\",\"PREDICTED_CHURN\",\"DATASET_TYPE\"]]\n",
    "\n",
    "output_label = [\"PREDICTED_CHURN\"]\n",
    "# Initialize a XGBClassifier object with input, label, and output column names\n",
    "model = XGBClassifier(\n",
    "    input_cols=feature_names_input,\n",
    "    label_cols=Target,\n",
    "    output_cols=output_label\n",
    "    \n",
    ")\n",
    "\n",
    "# Train the classifier model using the training set\n",
    "_ = model.fit(training_spdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0bedb9-b8b6-4f3f-ba56-66e59ef5d678",
   "metadata": {
    "collapsed": false,
    "name": "mk"
   },
   "source": [
    "## Log the model as a new version V2 with the same model name QS_CustomerChurn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a004951-afdc-4461-8d5e-efc2d4d4fef1",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "QS_CustomerChurn_classifier_v2"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.model import type_hints\n",
    "\n",
    "reg = Registry(session=session)\n",
    "\n",
    "MODEL_NAME = \"QS_CustomerChurn_classifier\"\n",
    "MODEL_VERSION = \"v2\"\n",
    "\n",
    "mv = reg.log_model(model,\n",
    "                   model_name=MODEL_NAME,\n",
    "                   version_name=MODEL_VERSION,\n",
    "                   options={'relax_version': True},\n",
    "                   task=type_hints.Task.TABULAR_BINARY_CLASSIFICATION)\n",
    "reg.show_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf1034-3a65-4202-bb66-e5662ffa21bf",
   "metadata": {
    "collapsed": false,
    "name": "modelmonitor"
   },
   "source": [
    "## Create a model monitor on the new model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6237f55-a907-4a97-ace3-d585bf0823c8",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CHURN_MODEL_MONITOR_NEW"
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL MONITOR CHURN_MODEL_MONITOR_NEW\n",
    "WITH\n",
    "    MODEL=QS_CustomerChurn_classifier\n",
    "    VERSION=v2\n",
    "    FUNCTION=predict\n",
    "    SOURCE=CUSTOMERS_EVAL\n",
    "    BASELINE=CUSTOMERS_TRAINING\n",
    "    TIMESTAMP_COLUMN=TRANSACTIONTIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(PREDICTED_CHURN)  \n",
    "    ACTUAL_CLASS_COLUMNS=(EXITED)\n",
    "    ID_COLUMNS=(CUSTOMERID)\n",
    "    WAREHOUSE=ML_WH\n",
    "    REFRESH_INTERVAL='1 min'\n",
    "    AGGREGATION_WINDOW='1 day';\n",
    "\"\"\"\n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a4231-7898-437e-ba01-534e407846d2",
   "metadata": {
    "collapsed": false,
    "name": "inference3"
   },
   "source": [
    "## Predict the churn on the new customer data with the retrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56381f7a-8ba7-4d84-9418-f0a974e4d747",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "inference_2"
   },
   "outputs": [],
   "source": [
    "status= inference('CUSTOMERS_EVAL','QS_CUSTOMERCHURN_CLASSIFIER', 'v2');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3e3d2-e91b-4b72-822a-24bc81bb7986",
   "metadata": {
    "collapsed": false,
    "name": "MODEL_MONITOR_STAT_METRIC"
   },
   "source": [
    "### Retrieve the statistical summaries of a feature, label, or model prediction from a monitored model over time.\n",
    "ðŸ”¹ Use Case: Helps analyze trends in model performance, feature behavior, and prediction distribution.Metric Name could be {â€˜COUNTâ€™, â€˜COUNT_NULLâ€™}\n",
    "### The granularity can be of any form â€˜<num> {DAY, WEEK, MONTH, QUARTER, YEAR}â€™ or ALL or NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a1cf5-e8b0-4ef4-bf77-10ae24476830",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "FEATURE_ML_MONITORING_METRICS_API"
   },
   "outputs": [],
   "source": [
    "\n",
    "SELECT * FROM \n",
    "TABLE(\n",
    "MODEL_MONITOR_STAT_METRIC(\n",
    "'CHURN_MODEL_MONITOR', 'COUNT', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-06'))\n",
    ") as a\n",
    "JOIN (SELECT * FROM \n",
    "TABLE(\n",
    "MODEL_MONITOR_STAT_METRIC(\n",
    "'CHURN_MODEL_MONITOR_NEW', 'COUNT', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-06'))\n",
    ")) as b ON a.EVENT_TIMESTAMP = b.EVENT_TIMESTAMP;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60655c57-1238-4097-9bcb-18e1bb18f098",
   "metadata": {
    "collapsed": false,
    "name": "MKMODEL_MONITOR_DRIFT_METRIC"
   },
   "source": [
    "### Compute drift metrics for a specified feature, label, or model prediction over a given time period. This helps detect changes in data distributions (feature drift) or prediction shifts (concept drift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e700c-b3ef-4189-b849-6dfe04f9eeaa",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "MODEL_MONITOR_DRIFT_METRIC"
   },
   "outputs": [],
   "source": [
    "\n",
    "SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n",
    "'CHURN_MODEL_MONITOR_NEW', 'DIFFERENCE_OF_MEANS', 'PREDICTED_CHURN', '1 DAY', TO_TIMESTAMP_TZ('2025-02-01'), TO_TIMESTAMP_TZ('2025-02-04')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58592dd9-9fd0-40a8-bd5c-1e7c7bee1115",
   "metadata": {
    "collapsed": false,
    "name": "performance_metrics"
   },
   "source": [
    "### Purpose: Fetches performance metrics for a monitored model over a specified time range.\n",
    "ðŸ”¹ Use Case: It allows tracking of how the model's performance has evolved (e.g., accuracy drops or performance degradation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8989d5-db2d-49c1-863b-7ea0d8f43fb0",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "MODEL_MONITOR_PERFORMANCE_METRIC"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TABLE(MODEL_MONITOR_PERFORMANCE_METRIC(\n",
    "'CHURN_MODEL_MONITOR_NEW', 'PRECISION', '1 DAY', TO_TIMESTAMP_TZ('2024-11-01'), TO_TIMESTAMP_TZ('2025-02-05')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb4ee0-07e5-4c11-aac8-bf7970e58451",
   "metadata": {
    "collapsed": false,
    "name": "setup_alert"
   },
   "source": [
    "### Setting up Alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f26f8-ce8a-41f0-9998-f9748f776ff3",
   "metadata": {
    "collapsed": false,
    "name": "TEST_NOTIFICATION"
   },
   "source": [
    "Setup Alerts to receive notification when a certain metric goes over threshold limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87216d35-8600-41a8-bfff-efcf5e545e04",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "test_notification_table"
   },
   "outputs": [],
   "source": [
    "query=f'''CREATE or replace TABLE TEST_NOTIFICATION(\n",
    "    notification varchar (100),\n",
    "    created_at timestamp\n",
    ");'''\n",
    "\n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb686f-099a-43c6-8420-0b017501a904",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "high_drift_alert"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE ALERT high_drift_alert\n",
    "    WAREHOUSE = ML_WH\n",
    "    SCHEDULE = '60 minutes'\n",
    "    IF ( EXISTS (SELECT * FROM TABLE(MODEL_MONITOR_DRIFT_METRIC(\n",
    "    'CHURN_MODEL_MONITOR', 'DIFFERENCE_OF_MEANS', 'PREDICTED_CHURN', '1 MONTH', TO_TIMESTAMP_TZ('2024-01-01'), TO_TIMESTAMP_TZ('2025-02-04')))))\n",
    "    THEN\n",
    "        INSERT INTO TEST_NOTIFICATION (notification, created_at) VALUES ('ALERT',(SELECT CURRENT_TIMESTAMP));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e2468-938a-4e17-bdb6-1706001133f2",
   "metadata": {
    "collapsed": false,
    "name": "end"
   },
   "source": [
    "## End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "lastEditStatus": {
   "authorEmail": "kala.govindarajan@snowflake.com",
   "authorId": "1099327464452",
   "authorName": "KGOVINDARAJAN",
   "lastEditTime": 1738988681329,
   "notebookId": "6pbwrdrp5nbc2qm775s3",
   "sessionId": "3b090c24-a8d1-4b35-9bf1-5724be97af5f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
