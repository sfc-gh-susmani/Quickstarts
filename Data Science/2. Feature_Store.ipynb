{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ddf336-59f3-47bd-b745-d4768364a384",
   "metadata": {
    "collapsed": false,
    "name": "overview_md"
   },
   "source": [
    "# Develop and Manage ML Models with Feature Store and Model Registry\n",
    "\n",
    "This notebook demonstrates an end-to-end ML experiment cycle including feature creation, training data generation, model training and inference. The workflow touches on key Snowflake ML features including [Snowflake Feature Store](https://docs.snowflake.com/en/developer-guide/snowpark-ml/feature-store/overview), [Dataset](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset), [Snowpark ML Modeling](https://docs.snowflake.com/en/developer-guide/snowpark-ml/modeling) and [Snowflake Model Registry](https://docs.snowflake.com/en/developer-guide/snowpark-ml/model-registry/overview). \n",
    "\n",
    "Note: Ensure `snowflake-ml-python` and `snowflake-snowpark-python` are installed from the packages dropdown\n",
    "\n",
    "**Table of contents**\n",
    "- Set up test environment\n",
    "  - Connect to Snowflake\n",
    "  - Select your example\n",
    "- Create features with Feature Store\n",
    "  - Initialize Feature Store\n",
    "  - Register entities and feature views\n",
    "  - Examine features in Snowflake UI\n",
    "- Generate Training Data\n",
    "- Train model with Snowpark ML\n",
    "- Log models in Model Registry\n",
    "  - Examine model in Snowflake UI\n",
    "- Predict with model\n",
    "  - Predict with local model\n",
    "  - Predict with Model Registry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7406a-828f-46d0-acfe-7f0e10f7c03d",
   "metadata": {
    "collapsed": false,
    "name": "setup_md"
   },
   "source": [
    "\n",
    "## Set up test environment\n",
    "\n",
    "### Connect to Snowflake\n",
    "\n",
    "Let's start with setting up our test environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3bf5a-9758-4341-ba46-c8399b502175",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "setup_notebook"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# Add a query tag to the session. This helps with debugging and performance monitoring.\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"aiml_notebooks_develop_models_with_feature_store\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\"}}\n",
    "\n",
    "# Set session context \n",
    "session.use_role(\"data_scientist\") \n",
    "model_prefix = session.get_current_user()\n",
    "\n",
    "# Print the current role, warehouse, and database/schema\n",
    "print(f\"role: {session.get_current_role()} | WH: {session.get_current_warehouse()} | DB.SCHEMA: {session.get_fully_qualified_current_schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f38d70d-ccc2-40b9-8020-50e3ad3ff165",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "set_schemas"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Schema SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO successfully created.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The schema where Feature Store will initialize on and test dataset stores.\n",
    "FS_DEMO_SCHEMA = session.get_current_schema()\n",
    "# the schema where the model lives.\n",
    "MODEL_DEMO_SCHEMA = session.get_current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f89f3-d84d-4226-830d-3a967499fed7",
   "metadata": {
    "collapsed": false,
    "name": "select_example_md"
   },
   "source": [
    "### Select your example\n",
    "\n",
    "We have prepared some examples that you can find in our [open source repo](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples). Each example contains the source dataset, feature view and entity definitions which will be used in this demo. `ExampleHelper` (included in snowflake-ml-python) will setup everything with simple APIs and you don't have to worry about the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cbb04de-193c-44e1-b400-802e22eb6941",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "example_list"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>LABEL_COLS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_york_taxi_features</td>\n",
       "      <td>Features using taxi trip data trying to predic...</td>\n",
       "      <td>TOTAL_AMOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_features</td>\n",
       "      <td>Features using synthetic airline data to predi...</td>\n",
       "      <td>DEPARTING_DELAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citibike_trip_features</td>\n",
       "      <td>Features using citibike trip data trying to pr...</td>\n",
       "      <td>tripduration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wine_quality_features</td>\n",
       "      <td>Features using wine quality data trying to pre...</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NAME                                               DESC  \\\n",
       "0  new_york_taxi_features  Features using taxi trip data trying to predic...   \n",
       "1        airline_features  Features using synthetic airline data to predi...   \n",
       "2  citibike_trip_features  Features using citibike trip data trying to pr...   \n",
       "3   wine_quality_features  Features using wine quality data trying to pre...   \n",
       "\n",
       "        LABEL_COLS  \n",
       "0     TOTAL_AMOUNT  \n",
       "1  DEPARTING_DELAY  \n",
       "2     tripduration  \n",
       "3          quality  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowflake.ml.feature_store.examples.example_helper import ExampleHelper\n",
    "\n",
    "example_helper = ExampleHelper(session, session.get_current_database(), FS_DEMO_SCHEMA)\n",
    "example_helper.list_examples().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f909c72-e3c0-4834-a935-24a689101979",
   "metadata": {
    "collapsed": false,
    "name": "load_example_md"
   },
   "source": [
    "`load_example()` will load the source data into Snowflake tables. In the example below, we are using the “new_york_taxi_features” example. You can replace this with any example listed above. Execution of the cell below may take some time depending on the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c12da2-71cc-4c90-89aa-b1bd474ae975",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "load_example"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AIRLINE_FEATURE_STORE\".SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO.nyc_yellow_trips:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VENDORID</th>\n",
       "      <th>PASSENGER_COUNT</th>\n",
       "      <th>TRIP_DISTANCE</th>\n",
       "      <th>RATECODEID</th>\n",
       "      <th>STORE_AND_FWD_FLAG</th>\n",
       "      <th>PULOCATIONID</th>\n",
       "      <th>DOLOCATIONID</th>\n",
       "      <th>PAYMENT_TYPE</th>\n",
       "      <th>FARE_AMOUNT</th>\n",
       "      <th>EXTRA</th>\n",
       "      <th>MTA_TAX</th>\n",
       "      <th>TIP_AMOUNT</th>\n",
       "      <th>TOLLS_AMOUNT</th>\n",
       "      <th>IMPROVEMENT_SURCHARGE</th>\n",
       "      <th>TOTAL_AMOUNT</th>\n",
       "      <th>CONGESTION_SURCHARGE</th>\n",
       "      <th>AIRPORT_FEE</th>\n",
       "      <th>TPEP_PICKUP_DATETIME</th>\n",
       "      <th>TPEP_DROPOFF_DATETIME</th>\n",
       "      <th>TRIP_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:53:47</td>\n",
       "      <td>2016-01-07 17:55:29</td>\n",
       "      <td>2195456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:37:22</td>\n",
       "      <td>2016-01-07 17:46:17</td>\n",
       "      <td>2195457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:08:42</td>\n",
       "      <td>2016-01-07 17:16:12</td>\n",
       "      <td>2195458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>162</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:27:16</td>\n",
       "      <td>2016-01-07 17:42:22</td>\n",
       "      <td>2195459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-07 17:46:03</td>\n",
       "      <td>2016-01-07 17:56:03</td>\n",
       "      <td>2195460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VENDORID  PASSENGER_COUNT  TRIP_DISTANCE  RATECODEID STORE_AND_FWD_FLAG  \\\n",
       "0         2                1           0.65           1                  N   \n",
       "1         2                1           1.24           1                  N   \n",
       "2         1                1           0.90           1                  N   \n",
       "3         1                1           2.50           1                  N   \n",
       "4         1                1           1.20           1                  N   \n",
       "\n",
       "   PULOCATIONID  DOLOCATIONID  PAYMENT_TYPE  FARE_AMOUNT  EXTRA  MTA_TAX  \\\n",
       "0           238           238             2          4.0    1.0      0.5   \n",
       "1           138            70             2          7.5    1.0      0.5   \n",
       "2           161           229             2          6.5    1.0      0.5   \n",
       "3           162           262             1         12.0    1.0      0.5   \n",
       "4           262           141             2          8.0    1.0      0.5   \n",
       "\n",
       "   TIP_AMOUNT  TOLLS_AMOUNT  IMPROVEMENT_SURCHARGE  TOTAL_AMOUNT  \\\n",
       "0         0.0           0.0                    0.3           5.8   \n",
       "1         0.0           0.0                    0.3           9.3   \n",
       "2         0.0           0.0                    0.3           8.3   \n",
       "3         1.0           0.0                    0.3          14.8   \n",
       "4         0.0           0.0                    0.3           9.8   \n",
       "\n",
       "   CONGESTION_SURCHARGE  AIRPORT_FEE TPEP_PICKUP_DATETIME  \\\n",
       "0                   NaN          NaN  2016-01-07 17:53:47   \n",
       "1                   NaN          NaN  2016-01-07 17:37:22   \n",
       "2                   NaN          NaN  2016-01-07 17:08:42   \n",
       "3                   NaN          NaN  2016-01-07 17:27:16   \n",
       "4                   NaN          NaN  2016-01-07 17:46:03   \n",
       "\n",
       "  TPEP_DROPOFF_DATETIME  TRIP_ID  \n",
       "0   2016-01-07 17:55:29  2195456  \n",
       "1   2016-01-07 17:46:17  2195457  \n",
       "2   2016-01-07 17:16:12  2195458  \n",
       "3   2016-01-07 17:42:22  2195459  \n",
       "4   2016-01-07 17:56:03  2195460  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace the value with the example you want to run\n",
    "source_tables = example_helper.load_example('new_york_taxi_features')\n",
    "\n",
    "# display as Pandas DataFrame\n",
    "for table in source_tables:\n",
    "    print(f\"{table}:\")\n",
    "    df = session.table(table).limit(5).to_pandas()\n",
    "    df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b29b4-24f4-4984-b348-f7087b7a6b20",
   "metadata": {
    "collapsed": false,
    "name": "feature_store_md"
   },
   "source": [
    "## Create features with Feature Store\n",
    "\n",
    "### Initialize Feature Store\n",
    "\n",
    "Let's first create a feature store client. With `CREATE_IF_NOT_EXIST` mode, it will try to create a new Feature Store schema and all necessary feature store metadata if it doesn't exist already. It is required for the first time to set up a Feature Store. Afterwards, you can use `FAIL_IF_NOT_EXIST` mode to connect to an existing Feature Store. \n",
    "\n",
    "Note that the database being used must already exist. Feature Store will **NOT** try to create the database even in `CREATE_IF_NOT_EXIST` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff64e3c-6445-486e-a0fe-2949c973e0ee",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "initialize_feature_store"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode\n",
    ")\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=session.get_current_database(), \n",
    "    name=FS_DEMO_SCHEMA, \n",
    "    default_warehouse=session.get_current_warehouse(),\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c642cda-4a95-47e0-93f6-8f9dde285ff4",
   "metadata": {
    "collapsed": false,
    "name": "register_entities_and_feature_views_md"
   },
   "source": [
    "### Register entities and feature views\n",
    "\n",
    "Next we register new entities and feature views in Feature Store. Entities will be the join keys used to generate training data. Feature Views contains all the features you need for your model training and inference. We have entities and feature views for this example defined in our [open source repo](https://github.com/snowflakedb/snowflake-ml-python/tree/main/snowflake/ml/feature_store/examples). We will load the definitions with `load_entities()` and `load_draft_feature_views()` for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe57406-6834-428d-8772-8d7e1265b08b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "register_entities"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "|\"NAME\"        |\"JOIN_KEYS\"       |\"DESC\"                 |\"OWNER\"   |\n",
      "----------------------------------------------------------------------\n",
      "|DOLOCATIONID  |[\"DOLOCATIONID\"]  |Drop off location id.  |ENGINEER  |\n",
      "|TRIP_ID       |[\"TRIP_ID\"]       |Trip id.               |ENGINEER  |\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_entities = []\n",
    "for e in example_helper.load_entities():\n",
    "    entity = fs.register_entity(e)\n",
    "    all_entities.append(entity)\n",
    "fs.list_entities().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415e5e69-d605-4285-bb8b-e4d378cc35e9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "register_feature_views"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"      |\"VERSION\"  |\"DESC\"                                              |\"REFRESH_FREQ\"  |\n",
      "------------------------------------------------------------------------------------------------\n",
      "|F_LOCATION  |1.0        |Features aggregated by location id and refreshe...  |12 hours        |\n",
      "|F_TRIP      |1.0        |Features per trip refreshed every day.              |1 day           |\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_feature_views = []\n",
    "for fv in example_helper.load_draft_feature_views():\n",
    "    rf = fs.register_feature_view(\n",
    "        feature_view=fv,\n",
    "        version='1.0'\n",
    "    )\n",
    "    all_feature_views.append(rf)\n",
    "\n",
    "fs.list_feature_views().select('name', 'version', 'desc', 'refresh_freq').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8daa62-4f51-4597-b8e5-812a0fc6f955",
   "metadata": {
    "name": "examine_features_md"
   },
   "source": [
    "We can examine all features in a feature view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8474a2-72c3-4c54-a4a3-7c3d97b7a9a4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "examine_features"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_LOCATION/1.0 has features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_FARE_1H</td>\n",
       "      <td>Averaged fare in past 1 hour window aggregated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVG_FARE_10H</td>\n",
       "      <td>Averaged fare in past 10 hours aggregated by l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name                                               Desc\n",
       "0   AVG_FARE_1H  Averaged fare in past 1 hour window aggregated...\n",
       "1  AVG_FARE_10H  Averaged fare in past 10 hours aggregated by l..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_TRIP/1.0 has features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSENGER_COUNT</td>\n",
       "      <td>The count of passenger of a trip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRIP_DISTANCE</td>\n",
       "      <td>The distance of a trip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FARE_AMOUNT</td>\n",
       "      <td>The fare of a trip.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                               Desc\n",
       "0  PASSENGER_COUNT  The count of passenger of a trip.\n",
       "1    TRIP_DISTANCE            The distance of a trip.\n",
       "2      FARE_AMOUNT                The fare of a trip."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for fv in all_feature_views:\n",
    "    print(f\"{fv.name}/{fv.version} has features:\")\n",
    "    pd.DataFrame(fv.feature_descs.items(), columns=['Name', 'Desc']).style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1febc16-4aee-4fd1-a8a1-9bec833243cc",
   "metadata": {
    "collapsed": false,
    "name": "examine_features_ui_md"
   },
   "source": [
    "### Examine features in Snowflake UI\n",
    "Now you should be able to see registered entities and feature views in Snowflake UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2908f-3033-4407-89e7-6761d32f8c19",
   "metadata": {
    "collapsed": false,
    "name": "generate_data_md"
   },
   "source": [
    "## Generate Training Data\n",
    "\n",
    "After our feature pipelines are fully setup, we can use them to generate [Snowflake Dataset](https://docs.snowflake.com/en/developer-guide/snowpark-ml/dataset) and later do model training. Generating training data is easy since materialized FeatureViews already carry most of the metadata like join keys, timestamp for point-in-time lookup, etc. We just need to provide the spine data (it's called spine because it is the list of entity IDs that we are essentially enriching by joining features with it).\n",
    "\n",
    "`generate_dataset()` returns a Snowflake Dataset object, which is best for distributed training with deep learning frameworks like TensorFlow or Pytorch which requires fine-grained file-level access. It creates a new Dataset object (which is versioned and immutable) in Snowflake which materializes the data in Parquet files. If you train models with classic ML libraries like Snowpark ML or scikit-learn, you can use `generate_training_set()` which returns a classic Snowflake table. The Cell below demonstrates `generate_dataset()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec901a65-f3ee-4c12-b8ff-ec0f630e5372",
   "metadata": {
    "collapsed": false,
    "name": "retrieve_metadata_md"
   },
   "source": [
    "Retrieve some metadata columns that are essential when generating training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c80b76-99a4-4eb0-b0cb-583afa434ecf",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "retrieve_metadata"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp col: TPEP_PICKUP_DATETIME\n",
      "excluded cols: []\n",
      "label cols: ['TOTAL_AMOUNT']\n",
      "join keys: ['TRIP_ID', 'DOLOCATIONID']\n",
      "training spine table: \"AIRLINE_FEATURE_STORE\".SNOWFLAKE_FEATURE_STORE_NOTEBOOK_DEMO.nyc_yellow_trips\n"
     ]
    }
   ],
   "source": [
    "label_cols = example_helper.get_label_cols()\n",
    "timestamp_col = example_helper.get_training_data_timestamp_col()\n",
    "excluded_cols = example_helper.get_excluded_cols()\n",
    "join_keys = [key for entity in all_entities for key in entity.join_keys]\n",
    "spine_table = example_helper.get_training_spine_table()\n",
    "print(f'timestamp col: {timestamp_col}')\n",
    "print(f'excluded cols: {excluded_cols}')\n",
    "print(f'label cols: {label_cols}')\n",
    "print(f'join keys: {join_keys}')\n",
    "print(f'training spine table: {spine_table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66ad1d-5ad1-4ad8-92f9-c65be491e0c3",
   "metadata": {
    "name": "create_spline_md"
   },
   "source": [
    "Create a spine dataframe that's sampled from source table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea00fe3a-ac16-45d7-95c0-7ea7ed344e79",
   "metadata": {
    "language": "python",
    "name": "create_spline"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "|\"TOTAL_AMOUNT\"  |\"TRIP_ID\"  |\"DOLOCATIONID\"  |\"TPEP_PICKUP_DATETIME\"  |\n",
      "------------------------------------------------------------------------\n",
      "|11.8            |4391772    |236             |2016-01-13 15:28:31     |\n",
      "|6.8             |9640580    |231             |2016-01-28 21:47:03     |\n",
      "|10.3            |8986296    |162             |2016-01-27 06:44:50     |\n",
      "|20.35           |4689446    |261             |2016-01-14 09:29:27     |\n",
      "|19.89           |9360850    |166             |2016-01-28 07:33:07     |\n",
      "|6.3             |9335036    |211             |2016-01-28 04:46:46     |\n",
      "|72.92           |5223446    |264             |2016-01-15 17:21:27     |\n",
      "|16.3            |4578405    |116             |2016-01-13 23:35:00     |\n",
      "|7.3             |5045083    |163             |2016-01-15 07:10:06     |\n",
      "|10.3            |9733135    |145             |2016-01-29 05:14:06     |\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_count = 512\n",
    "source_df = session.sql(f\"\"\"\n",
    "    select {','.join(label_cols)}, \n",
    "            {','.join(join_keys)} \n",
    "            {',' + timestamp_col if timestamp_col is not None else ''} \n",
    "    from {spine_table}\n",
    "\"\"\")\n",
    "spine_df = source_df.sample(n=sample_count)\n",
    "# preview spine dataframe\n",
    "spine_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8b59a-dcae-41a4-8954-db6719c5cf60",
   "metadata": {
    "name": "generate_dataset_md"
   },
   "source": [
    "Generate dataset object from spine dataframe and feature views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85993d-3b1a-41d5-af13-96b7c2716e74",
   "metadata": {
    "language": "python",
    "name": "generate_dataset"
   },
   "outputs": [],
   "source": [
    "my_dataset = fs.generate_dataset(\n",
    "    name=f\"my_cool_training_dataset_{model_prefix}\",\n",
    "    spine_df=spine_df, \n",
    "    features=all_feature_views,\n",
    "    version=\"4.0\",\n",
    "    spine_timestamp_col=timestamp_col,\n",
    "    spine_label_cols=label_cols,\n",
    "    exclude_columns=excluded_cols,\n",
    "    desc=\"This is the dataset joined spine dataframe with feature views\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cf2f4-59b3-40da-8c43-bee27129105d",
   "metadata": {
    "name": "view_dataset_md"
   },
   "source": [
    "Convert dataset to a snowpark dataframe and examine all the features in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3c71aa-1c6b-4bf4-83f9-2176dc249f83",
   "metadata": {
    "language": "python",
    "name": "view_dataset"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_AMOUNT</th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>DOLOCATIONID</th>\n",
       "      <th>TPEP_PICKUP_DATETIME</th>\n",
       "      <th>AVG_FARE_1H</th>\n",
       "      <th>AVG_FARE_10H</th>\n",
       "      <th>PASSENGER_COUNT</th>\n",
       "      <th>TRIP_DISTANCE</th>\n",
       "      <th>FARE_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>9753533</td>\n",
       "      <td>228</td>\n",
       "      <td>2016-01-29 07:50:17-08:00</td>\n",
       "      <td>42.083332</td>\n",
       "      <td>25.560465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.800000</td>\n",
       "      <td>337386</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-01 23:27:54-08:00</td>\n",
       "      <td>9.713513</td>\n",
       "      <td>10.708535</td>\n",
       "      <td>2</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.250000</td>\n",
       "      <td>521354</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-02 16:00:37-08:00</td>\n",
       "      <td>10.513055</td>\n",
       "      <td>9.510478</td>\n",
       "      <td>3</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.799999</td>\n",
       "      <td>536727</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-02 17:30:49-08:00</td>\n",
       "      <td>11.397975</td>\n",
       "      <td>9.790948</td>\n",
       "      <td>5</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.300000</td>\n",
       "      <td>1059372</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-01-04 11:12:42-08:00</td>\n",
       "      <td>10.893401</td>\n",
       "      <td>9.468452</td>\n",
       "      <td>1</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>38.299999</td>\n",
       "      <td>371165</td>\n",
       "      <td>244</td>\n",
       "      <td>2016-01-02 02:56:18-08:00</td>\n",
       "      <td>23.259615</td>\n",
       "      <td>22.674618</td>\n",
       "      <td>1</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>21.799999</td>\n",
       "      <td>4212437</td>\n",
       "      <td>244</td>\n",
       "      <td>2016-01-13 04:03:58-08:00</td>\n",
       "      <td>22.120001</td>\n",
       "      <td>22.395477</td>\n",
       "      <td>1</td>\n",
       "      <td>7.170000</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>42.349998</td>\n",
       "      <td>7530490</td>\n",
       "      <td>244</td>\n",
       "      <td>2016-01-21 17:51:06-08:00</td>\n",
       "      <td>25.574074</td>\n",
       "      <td>23.103773</td>\n",
       "      <td>1</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>14.300000</td>\n",
       "      <td>7304440</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-21 03:12:42-08:00</td>\n",
       "      <td>8.818182</td>\n",
       "      <td>10.719931</td>\n",
       "      <td>1</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>66.949997</td>\n",
       "      <td>10352420</td>\n",
       "      <td>97</td>\n",
       "      <td>2016-01-30 16:03:07-08:00</td>\n",
       "      <td>17.518518</td>\n",
       "      <td>15.804812</td>\n",
       "      <td>2</td>\n",
       "      <td>20.299999</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TOTAL_AMOUNT   TRIP_ID  DOLOCATIONID      TPEP_PICKUP_DATETIME  \\\n",
       "0        6.300000   9753533           228 2016-01-29 07:50:17-08:00   \n",
       "1       -4.800000    337386           161 2016-01-01 23:27:54-08:00   \n",
       "2       12.250000    521354           161 2016-01-02 16:00:37-08:00   \n",
       "3       18.799999    536727           161 2016-01-02 17:30:49-08:00   \n",
       "4       15.300000   1059372           161 2016-01-04 11:12:42-08:00   \n",
       "..            ...       ...           ...                       ...   \n",
       "507     38.299999    371165           244 2016-01-02 02:56:18-08:00   \n",
       "508     21.799999   4212437           244 2016-01-13 04:03:58-08:00   \n",
       "509     42.349998   7530490           244 2016-01-21 17:51:06-08:00   \n",
       "510     14.300000   7304440             4 2016-01-21 03:12:42-08:00   \n",
       "511     66.949997  10352420            97 2016-01-30 16:03:07-08:00   \n",
       "\n",
       "     AVG_FARE_1H  AVG_FARE_10H  PASSENGER_COUNT  TRIP_DISTANCE  FARE_AMOUNT  \n",
       "0      42.083332     25.560465                1       0.800000          5.5  \n",
       "1       9.713513     10.708535                2       0.150000         -3.5  \n",
       "2      10.513055      9.510478                3       1.110000          9.0  \n",
       "3      11.397975      9.790948                5       2.500000         16.0  \n",
       "4      10.893401      9.468452                1       2.500000         12.5  \n",
       "..           ...           ...              ...            ...          ...  \n",
       "507    23.259615     22.674618                1      13.300000         37.0  \n",
       "508    22.120001     22.395477                1       7.170000         20.5  \n",
       "509    25.574074     23.103773                1       7.900000         33.5  \n",
       "510     8.818182     10.719931                1       2.680000         12.0  \n",
       "511    17.518518     15.804812                2      20.299999         55.0  \n",
       "\n",
       "[512 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df = my_dataset.read.to_snowpark_dataframe()\n",
    "assert training_data_df.count() == sample_count\n",
    "# drop rows that have any nulls in value. \n",
    "training_data_df = training_data_df.dropna(how='any')\n",
    "training_data_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da355bc-08f3-4052-8c9c-b5a9458677a8",
   "metadata": {
    "collapsed": false,
    "name": "train_model_md"
   },
   "source": [
    "## Train model with Snowpark ML\n",
    "\n",
    "Now let's train a simple random forest model, and evaluate the prediction accuracy. When you call fit() on a DataFrame that is created from a  Dataset, the linkage between the trained model and dataset is automatically wired up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d355cb-9b5b-4aca-92ec-16cfe67118db",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "train_model"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature cols: ['TRIP_DISTANCE', 'FARE_AMOUNT', 'AVG_FARE_10H', 'PASSENGER_COUNT', 'AVG_FARE_1H']\n",
      "MSE: 8.587654420611477, Accuracy: 99.83667856616516\n"
     ]
    }
   ],
   "source": [
    "from snowflake.ml.modeling.ensemble import RandomForestRegressor\n",
    "from snowflake.ml.modeling import metrics as snowml_metrics\n",
    "from snowflake.snowpark.functions import abs as sp_abs, mean, col\n",
    "\n",
    "def train_model_using_snowpark_ml(training_data_df):\n",
    "    train, test = training_data_df.random_split([0.8, 0.2], seed=42)\n",
    "    feature_columns = list(set(training_data_df.columns) - set(label_cols) - set(join_keys) - set([timestamp_col]))\n",
    "    print(f\"feature cols: {feature_columns}\")\n",
    "    \n",
    "    rf = RandomForestRegressor(\n",
    "        input_cols=feature_columns, label_cols=label_cols, \n",
    "        max_depth=3, n_estimators=20, random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(train)\n",
    "    predictions = rf.predict(test)\n",
    "\n",
    "    output_label_names = ['OUTPUT_' + col for col in label_cols]\n",
    "    mse = snowml_metrics.mean_squared_error(\n",
    "        df=predictions, \n",
    "        y_true_col_names=label_cols, \n",
    "        y_pred_col_names=output_label_names\n",
    "    )\n",
    "\n",
    "    accuracy = 100 - snowml_metrics.mean_absolute_percentage_error(\n",
    "        df=predictions,\n",
    "        y_true_col_names=label_cols,\n",
    "        y_pred_col_names=output_label_names\n",
    "    )\n",
    "\n",
    "    print(f\"MSE: {mse}, Accuracy: {accuracy}\")\n",
    "    return rf\n",
    "\n",
    "random_forest_model = train_model_using_snowpark_ml(training_data_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b12493-3339-4369-82d4-46a4389f6bf1",
   "metadata": {
    "collapsed": false,
    "name": "model_registry_md"
   },
   "source": [
    "## Log model in Model Registry\n",
    "\n",
    "After the model is trained, we can save the model into Model Registry so we can manage the model, its metadata including metrics, versions, and use it later for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1209a6-4c8c-4441-9c5d-7688f4ec0233",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_registry"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "registry = Registry(\n",
    "    session=session, \n",
    "    database_name=session.get_current_database(), \n",
    "    schema_name=MODEL_DEMO_SCHEMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcf485-9c9a-4a74-a8a2-3154c8f5aa74",
   "metadata": {
    "name": "log_model_md"
   },
   "source": [
    "Log model into Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2ec74-fd46-445d-8fe9-1b133e4284eb",
   "metadata": {
    "language": "python",
    "name": "log_model"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wezhou/miniconda3/envs/py38/lib/python3.8/contextlib.py:113: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelVersion(\n",
       "  name='MY_RANDOM_FOREST_REGRESSOR_MODEL',\n",
       "  version='V1',\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f\"MY_RANDOM_FOREST_REGRESSOR_MODEL_{model_prefix}\"\n",
    "\n",
    "registry.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name=\"v1\",\n",
    "    model=random_forest_model,\n",
    "    comment=\"My model trained with feature views, dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7eaf0c-a31b-40e0-acdd-1dc4fb9ecb4f",
   "metadata": {
    "collapsed": false,
    "name": "model_registry_ui_md"
   },
   "source": [
    "### Examine model in Snowflake UI\n",
    "Now you should be able to see the model in Snowflake UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387a446-4a7e-4347-9f41-01b56d1cd39a",
   "metadata": {
    "collapsed": false,
    "name": "predict_md"
   },
   "source": [
    "## Predict with model\n",
    "\n",
    "Finally we are almost ready for prediction! For this, we can look up the latest feature values from Feature Store for the specific data records that we are running prediction on. One of the key benefits of using the Feature Store is that it provides a way to automatically serve up the right feature values during prediction with point-in-time correct feature values. `load_feature_views_from_dataset()` gets the same feature views used in training, then `retrieve_feature_values()` lookups the latest feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2f001a-732a-4c0b-b02d-b3cdab5422ee",
   "metadata": {
    "language": "python",
    "name": "test_dataset"
   },
   "outputs": [],
   "source": [
    "test_df = source_df.sample(n=3)\n",
    "\n",
    "# load back feature views from dataset\n",
    "fvs = fs.load_feature_views_from_dataset(my_dataset)\n",
    "enriched_df = fs.retrieve_feature_values(\n",
    "    test_df, \n",
    "    features=fvs,\n",
    "    exclude_columns=join_keys,\n",
    "    spine_timestamp_col=timestamp_col\n",
    ")\n",
    "enriched_df = enriched_df.drop(join_keys)\n",
    "enriched_pd = enriched_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2f69f-1597-4f43-9b59-554c48112a47",
   "metadata": {
    "collapsed": false,
    "name": "predict_local_md"
   },
   "source": [
    "### [Optional 1] predict with local model\n",
    "Now we can predict with a local model and the feature values retrieved from feature store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6307ba80-532e-4b5f-90f6-8b162e740702",
   "metadata": {
    "language": "python",
    "name": "predict_local"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TOTAL_AMOUNT TPEP_PICKUP_DATETIME  AVG_FARE_1H  AVG_FARE_10H  \\\n",
      "0         15.96  2016-01-07 10:26:02     9.440415      9.324965   \n",
      "1         10.55  2016-01-01 18:44:40    10.083333      9.236685   \n",
      "2         17.80  2016-01-29 21:05:54    10.385390     10.287410   \n",
      "\n",
      "   PASSENGER_COUNT  TRIP_DISTANCE  FARE_AMOUNT  OUTPUT_TOTAL_AMOUNT  \n",
      "0                1           2.23         12.5            16.440312  \n",
      "1                1           1.70          7.0             8.523669  \n",
      "2                1           3.11         16.5            18.717726  \n"
     ]
    }
   ],
   "source": [
    "pred = random_forest_model.predict(enriched_pd)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff6c72-77f8-4aee-aa76-dba0d0e70cd9",
   "metadata": {
    "collapsed": false,
    "name": "predict_reigstry_md"
   },
   "source": [
    "### [Option 2] Predict with Model Registry\n",
    "\n",
    "We can also retrieve the model from model registry and run  predictions on the model using latest feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd0ef2d-2d4f-4dfd-a6c5-3eee960ea5a0",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "predict_registry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TRIP_DISTANCE  FARE_AMOUNT  AVG_FARE_10H  PASSENGER_COUNT  AVG_FARE_1H  \\\n",
      "0           2.23         12.5      9.324965                1     9.440415   \n",
      "1           1.70          7.0      9.236685                1    10.083333   \n",
      "2           3.11         16.5     10.287410                1    10.385390   \n",
      "\n",
      "   OUTPUT_TOTAL_AMOUNT  \n",
      "0            16.440312  \n",
      "1             8.523669  \n",
      "2            18.717726  \n"
     ]
    }
   ],
   "source": [
    "# model is retrieved from Model Registry\n",
    "model = registry.get_model(model_name).version(\"v1\")\n",
    "restored_prediction = model.run(enriched_pd, function_name=\"predict\")\n",
    "print(restored_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
